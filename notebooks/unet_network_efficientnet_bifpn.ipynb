{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check efficientnet_b0 layer by layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0, Output size: torch.Size([1, 32, 112, 112])\n",
      "Layer: 1, Output size: torch.Size([1, 16, 112, 112])\n",
      "Layer: 2, Output size: torch.Size([1, 24, 56, 56])\n",
      "Layer: 3, Output size: torch.Size([1, 40, 28, 28])\n",
      "Layer: 4, Output size: torch.Size([1, 80, 14, 14])\n",
      "Layer: 5, Output size: torch.Size([1, 112, 14, 14])\n",
      "Layer: 6, Output size: torch.Size([1, 192, 7, 7])\n",
      "Layer: 7, Output size: torch.Size([1, 320, 7, 7])\n",
      "Layer: 8, Output size: torch.Size([1, 1280, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "efficientnet = torchvision.models.efficientnet_b0()\n",
    "features = efficientnet.features\n",
    "\n",
    "input_size = (3, 224, 224)\n",
    "\n",
    "input_tensor = torch.randn(1, *input_size)\n",
    "\n",
    "output = input_tensor\n",
    "for layer_name, layer in features.named_children():\n",
    "    output = layer(output)\n",
    "    print(f\"Layer: {layer_name}, Output size: {output.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EffcientNetB0 as encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EfficientNet, self).__init__()\n",
    "        efficientnet = torchvision.models.efficientnet_b0()\n",
    "        features = efficientnet.features\n",
    "        self.layer1 = features[:3]\n",
    "        self.layer2 = features[3]\n",
    "        self.layer3 = features[4]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        return x1, x2, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet = EfficientNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 24, 56, 56]),\n",
       " torch.Size([1, 40, 28, 28]),\n",
       " torch.Size([1, 80, 14, 14]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = efficientnet(input_tensor)\n",
    "\n",
    "output[0].shape, output[1].shape, output[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiFPN(nn.Module):\n",
    "    def __init__(self, fpn_sizes):\n",
    "        super(BiFPN, self).__init__()\n",
    "\n",
    "        P4_channels, P5_channels, P6_channels = fpn_sizes\n",
    "        self.W_bifpn = 64\n",
    "\n",
    "        self.p6_td_conv = nn.Conv2d(\n",
    "            P6_channels, self.W_bifpn, kernel_size=3, stride=1, bias=True, padding=1\n",
    "        )\n",
    "        self.p6_td_conv_2 = nn.Conv2d(\n",
    "            self.W_bifpn,\n",
    "            self.W_bifpn,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            groups=self.W_bifpn,\n",
    "            bias=True,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.p6_td_act = nn.ReLU()\n",
    "        self.p6_td_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n",
    "        self.p6_td_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p6_td_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "        self.p5_td_conv = nn.Conv2d(\n",
    "            P5_channels, self.W_bifpn, kernel_size=3, stride=1, bias=True, padding=1\n",
    "        )\n",
    "        self.p5_td_conv_2 = nn.Conv2d(\n",
    "            self.W_bifpn,\n",
    "            self.W_bifpn,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            groups=self.W_bifpn,\n",
    "            bias=True,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.p5_td_act = nn.ReLU()\n",
    "        self.p5_td_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n",
    "        self.p5_td_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p5_td_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "        self.p4_td_conv = nn.Conv2d(\n",
    "            P4_channels, self.W_bifpn, kernel_size=3, stride=1, bias=True, padding=1\n",
    "        )\n",
    "        self.p4_td_conv_2 = nn.Conv2d(\n",
    "            self.W_bifpn,\n",
    "            self.W_bifpn,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            groups=self.W_bifpn,\n",
    "            bias=True,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.p4_td_act = nn.ReLU()\n",
    "        self.p4_td_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n",
    "        self.p4_td_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p4_td_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p5_upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "        self.p3_out_conv_2 = nn.Conv2d(\n",
    "            self.W_bifpn,\n",
    "            self.W_bifpn,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            groups=self.W_bifpn,\n",
    "            bias=True,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.p3_out_act = nn.ReLU()\n",
    "        self.p3_out_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n",
    "        self.p3_out_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p3_out_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p3_downsample = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.p4_out_conv = nn.Conv2d(\n",
    "            self.W_bifpn,\n",
    "            self.W_bifpn,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            groups=self.W_bifpn,\n",
    "            bias=True,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.p4_out_act = nn.ReLU()\n",
    "        self.p4_out_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n",
    "        self.p4_out_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p4_out_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p4_out_w3 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p4_upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "        self.p5_out_conv = nn.Conv2d(\n",
    "            self.W_bifpn,\n",
    "            self.W_bifpn,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            groups=self.W_bifpn,\n",
    "            bias=True,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.p5_out_act = nn.ReLU()\n",
    "        self.p5_out_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n",
    "        self.p5_out_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p5_out_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p5_out_w3 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p4_downsample = nn.MaxPool2d(kernel_size=2)\n",
    "        self.p5_downsample = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.p6_out_conv = nn.Conv2d(\n",
    "            self.W_bifpn,\n",
    "            self.W_bifpn,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            groups=self.W_bifpn,\n",
    "            bias=True,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.p6_out_act = nn.ReLU()\n",
    "        self.p6_out_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n",
    "        self.p6_out_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p6_out_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p6_out_w3 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p6_upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "        self.p7_out_conv_2 = nn.Conv2d(\n",
    "            self.W_bifpn,\n",
    "            self.W_bifpn,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            groups=self.W_bifpn,\n",
    "            bias=True,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.p7_out_act = nn.ReLU()\n",
    "        self.p7_out_conv_bn = nn.BatchNorm2d(self.W_bifpn)\n",
    "        self.p7_out_w1 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "        self.p7_out_w2 = torch.tensor(1, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        epsilon = 0.0001\n",
    "        P4, P5, P6 = inputs\n",
    "\n",
    "        P6_td_inp = self.p6_td_conv(P6)\n",
    "        P6_td = self.p6_td_conv_2((self.p6_td_w1 * P6_td_inp) / (self.p6_td_w1 + epsilon))\n",
    "        P6_td = self.p6_td_act(P6_td)\n",
    "        P6_td = self.p6_td_conv_bn(P6_td)\n",
    "\n",
    "        P5_td_inp = self.p5_td_conv(P5)\n",
    "        P5_td = self.p5_td_conv_2(\n",
    "            (self.p5_td_w1 * P5_td_inp + self.p5_td_w2 * self.p6_upsample(P6_td))\n",
    "            / (self.p5_td_w1 + self.p5_td_w2 + epsilon)\n",
    "        )\n",
    "        P5_td = self.p5_td_act(P5_td)\n",
    "        P5_td = self.p5_td_conv_bn(P5_td)\n",
    "\n",
    "        P4_td_inp = self.p4_td_conv(P4)\n",
    "        P4_td = self.p4_td_conv_2(\n",
    "            (self.p4_td_w1 * P4_td_inp + self.p4_td_w2 * self.p5_upsample(P5_td))\n",
    "            / (self.p4_td_w1 + self.p4_td_w2 + epsilon)\n",
    "        )\n",
    "        P4_td = self.p4_td_act(P4_td)\n",
    "        P4_td = self.p4_td_conv_bn(P4_td)\n",
    "\n",
    "        P4_out = self.p4_out_conv(\n",
    "            (self.p4_out_w1 * P4_td_inp + self.p4_out_w2 * P4_td)\n",
    "            / (self.p4_out_w1 + self.p4_out_w2 + epsilon)\n",
    "        )\n",
    "        P4_out = self.p4_out_act(P4_out)\n",
    "        P4_out = self.p4_out_conv_bn(P4_out)\n",
    "\n",
    "        P5_out = self.p5_out_conv(\n",
    "            (\n",
    "                self.p5_out_w1 * P5_td_inp\n",
    "                + self.p5_out_w2 * P5_td\n",
    "                + self.p5_out_w3 * self.p4_downsample(P4_out)\n",
    "            )\n",
    "            / (self.p5_out_w2 + self.p5_out_w3 + epsilon)\n",
    "        )\n",
    "        P5_out = self.p5_out_act(P5_out)\n",
    "        P5_out = self.p5_out_conv_bn(P5_out)\n",
    "\n",
    "        P6_out = self.p6_out_conv(\n",
    "            (\n",
    "                self.p6_out_w1 * P6_td_inp\n",
    "                + self.p6_out_w2 * P6_td\n",
    "                + self.p6_out_w3 * self.p5_downsample(P5_out)\n",
    "            )\n",
    "            / (self.p6_out_w1 + self.p6_out_w2 + self.p6_out_w3 + epsilon)\n",
    "        )\n",
    "        P6_out = self.p6_out_act(P6_out)\n",
    "        P6_out = self.p6_out_conv_bn(P6_out)\n",
    "\n",
    "        return [P4_out, P5_out, P6_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bifpn = BiFPN([40, 112, 192])\n",
    "\n",
    "c1 = torch.randn([1, 40, 64, 64])\n",
    "c2 = torch.randn([1, 112, 32, 32])\n",
    "c3 = torch.randn([1, 192, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bifpn([c1, c2, c3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64, 64, 64]),\n",
       " torch.Size([1, 64, 32, 32]),\n",
       " torch.Size([1, 64, 16, 16]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape, output[1].shape, output[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example model - EfficientNetB0 + BiFPN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientDet(nn.Module):\n",
    "    def __init__(self, in_features=[24, 40, 80]):\n",
    "        super(EfficientDet, self).__init__()\n",
    "        self.encoder = EfficientNet()\n",
    "        self.decoder = BiFPN(in_features)\n",
    "        self.upsample_4 = nn.Upsample(scale_factor=4, mode=\"nearest\")\n",
    "        self.upsample_2 = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.final_conv = nn.Conv2d(in_channels=192, out_channels=1, kernel_size=3, padding=\"same\")\n",
    "\n",
    "    def upsample_cat(self, x):\n",
    "        p4, p5, p6 = x\n",
    "        p6 = self.upsample_4(p6)\n",
    "        p5 = self.upsample_2(p5)\n",
    "        return torch.cat([p4, p5, p6], dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2, x3 = self.encoder(x)\n",
    "        out = self.decoder([x1, x2, x3])\n",
    "        cated = self.upsample_cat(out)\n",
    "        return self.final_conv(cated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientDet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 56, 56]) torch.Size([1, 40, 28, 28]) torch.Size([1, 80, 14, 14])\n",
      "torch.Size([1, 64, 56, 56]) torch.Size([1, 64, 28, 28]) torch.Size([1, 64, 14, 14])\n",
      "torch.Size([1, 192, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 56, 56])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
