{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quantization steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.ao.quantization.quantize_fx as quantize_fx\n",
    "from tinynn.graph.quantization.quantizer import QATQuantizer\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from src.data.components.custom_transforms import BilinearInterpolation\n",
    "from src.data.components.nyu_dataset import NYUDataset\n",
    "from src.models.unet_module import UNETLitModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"logs/train/runs/2024-06-02_01-46-33/checkpoints/epoch_000.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNETLitModule.load_from_checkpoint(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fuse BatchNorm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fuse = quantize_fx.fuse_fx(model.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PTQ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_img = transforms.Compose([transforms.PILToTensor(), transforms.Resize((224, 224))])\n",
    "\n",
    "transforms_mask_train = transforms.Compose(\n",
    "    [transforms.ToTensor(), BilinearInterpolation((56, 56))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = NYUDataset(\n",
    "    \"nyu2_train.csv\", \"data/\", transform=transforms_img, target_transform=transforms_mask_train\n",
    ")\n",
    "\n",
    "data_train, data_val = random_split(\n",
    "    dataset=trainset,\n",
    "    lengths=[0.8, 0.2],\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(dataset=data_val, batch_size=32, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration(model, num_iterations, val_dataloader):\n",
    "    count = 0\n",
    "    for data in val_dataloader:\n",
    "        img, mask = data\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "            mask = mask.cuda()\n",
    "        model(img)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if count >= num_iterations:\n",
    "            break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer_per_tensor = QATQuantizer(\n",
    "    model,\n",
    "    torch.randn(1, 3, 52, 52),\n",
    "    work_dir=\"quant_output\",\n",
    "    config={\n",
    "        \"asymmetric\": True,\n",
    "        \"backend\": \"qnnpack\",\n",
    "        \"disable_requantization_for_cat\": True,\n",
    "        \"per_tensor\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "quantizer_per_channel = QATQuantizer(\n",
    "    model,\n",
    "    torch.randn(1, 3, 52, 52),\n",
    "    work_dir=\"quant_output\",\n",
    "    config={\n",
    "        \"asymmetric\": True,\n",
    "        \"backend\": \"qnnpack\",\n",
    "        \"disable_requantization_for_cat\": True,\n",
    "        \"per_tensor\": False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptq_model_with_quantizer_tensor = quantizer_per_tensor.quantize()\n",
    "ptq_model_with_quantizer_channel = quantizer_per_channel.quantize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptq_model_with_quantizer_tensor.to(\"cuda\")\n",
    "ptq_model_with_quantizer_channel.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post quantization calibration\n",
    "ptq_model_with_quantizer_tensor.apply(torch.quantization.disable_fake_quant)\n",
    "ptq_model_with_quantizer_tensor.apply(torch.quantization.enable_observer)\n",
    "ptq_model_with_quantizer_tensor = calibration(ptq_model_with_quantizer_tensor, 50, val_dataloader)\n",
    "\n",
    "ptq_model_with_quantizer_channel.apply(torch.quantization.disable_fake_quant)\n",
    "ptq_model_with_quantizer_channel.apply(torch.quantization.enable_observer)\n",
    "ptq_model_with_quantizer_channel = calibration(ptq_model_with_quantizer_tensor, 50, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable observer and enable fake quantization to validate model with quantization error\n",
    "ptq_model_with_quantizer_tensor.apply(torch.quantization.disable_observer)\n",
    "ptq_model_with_quantizer_tensor.apply(torch.quantization.enable_fake_quant)\n",
    "# ptq_model_with_quantizer_tensor(next(iter(val_dataloader))[0].to(\"cuda\"))\n",
    "\n",
    "ptq_model_with_quantizer_channel.apply(torch.quantization.disable_observer)\n",
    "ptq_model_with_quantizer_channel.apply(torch.quantization.enable_fake_quant)\n",
    "# ptq_model_with_quantizer_channel(next(iter(val_dataloader))[0].to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **QAT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer_per_tensor = QATQuantizer(\n",
    "    model,\n",
    "    torch.randn(1, 3, 52, 52),\n",
    "    work_dir=\"quant_output\",\n",
    "    config={\n",
    "        \"asymmetric\": True,\n",
    "        \"backend\": \"qnnpack\",\n",
    "        \"disable_requantization_for_cat\": True,\n",
    "        \"per_tensor\": True,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model = quantizer_per_tensor.quantize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model = calibration(qat_model, 50, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model.apply(torch.quantization.enable_fake_quant)\n",
    "qat_model.apply(torch.quantization.enable_observer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the model with quantization error via fake quantization\n",
    "qat_model.apply(torch.quantization.disable_observer)\n",
    "# validate here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def check_saved_pytorch_model_size(filepath):\n",
    "    if os.path.isfile(filepath):\n",
    "        size_bytes = os.path.getsize(filepath)\n",
    "        size_mb = size_bytes / (1024 * 1024)\n",
    "        return size_mb\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_saved_pytorch_model_size(\"ptq_tensor.pty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_saved_pytorch_model_size(\"ptq.pty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_saved_pytorch_model_size(\"qat.pty\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
